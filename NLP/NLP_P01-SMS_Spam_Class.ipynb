{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SMS Spam Classification Using Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Initialize lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message Class\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham\n",
       "5  FreeMsg Hey there darling it's been 3 week's n...  spam\n",
       "6  Even my brother is not like to speak with me. ...   ham\n",
       "7  As per your request 'Melle Melle (Oru Minnamin...   ham\n",
       "8  WINNER!! As a valued network customer you have...  spam\n",
       "9  Had your mobile 11 months or more? U R entitle...  spam"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "# Read the SMS spam collection dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Administrator\\OneDrive\\Desktop\\MLDS\\NLP\\Spam_SMS.csv').iloc[:,[1,0]]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "ham     4827\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    4827\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Convert ratings to binary (0 for negative, 1 for positive)\n",
    "df['Class'] = df['Class'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Text Preprocessing Pipeline\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    url_pattern = r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub('[^a-zA-Z0-9- ]+', '', text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    text = \" \".join(lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words)  \n",
    "    # Remove extra spaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freemsg hey darling 3 week word back id like f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobile 11 month u r entitled update latest col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  Class\n",
       "0  go jurong point crazy available bugis n great ...      0\n",
       "1                            ok lar joking wif u oni      0\n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...      1\n",
       "3                u dun say early hor u c already say      0\n",
       "4           nah dont think go usf life around though      0\n",
       "5  freemsg hey darling 3 week word back id like f...      1\n",
       "6      even brother like speak treat like aid patent      0\n",
       "7  per request melle melle oru minnaminunginte nu...      0\n",
       "8  winner valued network customer selected receiv...      1\n",
       "9  mobile 11 month u r entitled update latest col...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to all messages\n",
    "df['Message'] = df['Message'].apply(preprocess_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Message'], df['Class'],test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Extraction - Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize reviews for Word2Vec\n",
    "tokenized_reviews = [review.split() for review in X_train]\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_reviews,vector_size=300, window=5, min_count=2, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model.wv.index_to_key #Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to average word2vec vector for each review.\n",
    "# Returns zeros vector if no words are found in vocabulary\n",
    "def get_avg_word2vec(reviews, w2v_model, vector_size=300):\n",
    "    doc_vectors = []\n",
    "    for review in tqdm(reviews):\n",
    "        word_vectors = [w2v_model.wv[word] for word in review.split() if word in w2v_model.wv]\n",
    "        if word_vectors:\n",
    "            doc_vectors.append(np.mean(word_vectors, axis=0))\n",
    "        else:\n",
    "            doc_vectors.append(np.zeros(vector_size))\n",
    "    return np.array(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4459/4459 [00:00<00:00, 17694.52it/s]\n",
      "100%|██████████| 1115/1115 [00:00<00:00, 17698.82it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v = get_avg_word2vec(X_train, w2v_model)\n",
    "X_test_w2v = get_avg_word2vec(X_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Training and Evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score\n",
    "# Initialize classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2Vec Results:\n",
      "Word2Vec accuracy:  0.97847533632287\n",
      "Word2Vec F1_Score:  0.922077922077922\n",
      "Conf_Metrix:\n",
      " [[949   5]\n",
      " [ 19 142]]\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate with Word2Vec features\n",
    "rf_classifier_w2v=rf_classifier.fit(X_train_w2v, y_train)\n",
    "y_pred_w2v = rf_classifier_w2v.predict(X_test_w2v)\n",
    "print(\"\\nWord2Vec Results:\")\n",
    "print(\"Word2Vec accuracy: \",accuracy_score(y_test,y_pred_w2v))\n",
    "print(\"Word2Vec F1_Score: \",f1_score(y_test,y_pred_w2v))\n",
    "print(\"Conf_Metrix:\\n\",confusion_matrix(y_test, y_pred_w2v))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7:Manual predictions\n",
    "def predict_new_texts(texts, w2v_model, classifier):\n",
    "    # Preprocess new texts\n",
    "    processed_texts = [preprocess_text(text) for text in texts]\n",
    "    # Convert texts to vectors\n",
    "    text_vectors = get_avg_word2vec(processed_texts, w2v_model)\n",
    "    # Predict\n",
    "    predictions = classifier.predict(text_vectors)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 4143.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Classification Results:\n",
      "--------------------------------------------------\n",
      "Text: Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\n",
      "Classification: Ham\n",
      "--------------------------------------------------\n",
      "Text: Fine if that’s the way u feel. That’s the way its gota b\n",
      "Classification: Ham\n",
      "--------------------------------------------------\n",
      "Text: England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
      "Classification: Spam\n",
      "--------------------------------------------------\n",
      "Text: Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\n",
      "Classification: Spam\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\n",
    "\"Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\",\n",
    "\"Fine if that’s the way u feel. That’s the way its gota b\",\n",
    "\"England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\",\n",
    "\"Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\"]\n",
    "# Get predictions\n",
    "predictions = predict_new_texts(new_texts, w2v_model, rf_classifier)\n",
    "# Map predictions to labels\n",
    "sentiment_map = {0: 'Ham', 1: 'Spam', 2: 'Neutral', 3: 'Positive'}\n",
    "results = [sentiment_map[pred] for pred in predictions]\n",
    "# Print results\n",
    "print(\"\\nText Classification Results:\")\n",
    "print(\"-\" * 50)\n",
    "for text, result in zip(new_texts, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Classification: {result}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
